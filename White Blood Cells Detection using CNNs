PYTHONHASHSEED=0.5
#Documentation - If this variable is not set or set to random, a random value is used to seed the hashes of str, bytes and datetime objects
#If PYTHONHASHSEED is set to an integer value, it is used as a fixed seed for generating the hash() of the types covered by the hash randomization.
#Its purpose is to allow repeatable hashing, such as for selftests for the interpreter itself, or to allow a cluster of python processes to share hash values.
#The integer must be a decimal number in the range [0,4294967295]. Specifying the value 0 will disable hash randomization.

import numpy as np
from skimage import io

from keras.models import Sequential
from keras.layers import Dense, Conv3D, MaxPooling3D
from keras.initializers import glorot_uniform
from keras.callbacks import EarlyStopping

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

#Possible causes of Randomness in Deep Networks
# Randomness due to Weights and Biases Initialization
# Randomness due to Train Test Split function
# Randomness in Initialization, such as weights.
# Randomness in Regularization, such as dropout.
# Randomness in Layers, such as word embedding.
# Randomness in Optimization, such as stochastic optimization.
# Randomness from Using the GPU
# Randomness from Using a Third Party Library
# Randomness from Using a Sophisticated model which is complex that we may miss some randomess

# Fixing the Random Generators
np.random.seed(1)
tf.set_random_seed(2)

path = r'C:\Users\Karandeep\Downloads\Deep Learning\Project\WB cells\dataset-master'

# #Used for initial exploration. Not to be used as actual code
# #Defining the function that can read each image out of the ImageCollection object
# def custom_load_func_images(images): 
#     return io.imread(images)                            #Reads a single image

# #The load_func function usually defines the task that needs to be performed on each element of the images dataset
# images = io.ImageCollection(path + '/BloodImage_*.jpg', load_func = custom_load_func_images)
# print('No.of images total: ' + str(len(images)))
# print('Dimensions of a single image: ' + str(images[0].shape))

# #Ensuring that an image is successfully imported and can be displayed again from the imported array
# print('Ensuring that an image is successfully imported and can be displayed again from the imported array: ')
# io.imshow(images[0])

#TO SAVE MEMORY - we load images and reshape it in a single step

#Defining the function that can read each image out of the ImageCollection object and also RESHAPE it for CNN input
def custom_load_func_images(images): 
    images = io.imread(images)                            #Reads a single image
    images = np.reshape(images, (img.shape[0],img.shape[1],img.shape[2],1)) #Reshapes the image so that it can be used as input to the CNN
    return images

#The load_func function usually defines the task that needs to be performed on each element of the images dataset
images = io.ImageCollection(path + '/JPEGImages/BloodImage_*.jpg', load_func = custom_load_func_images)
print('No.of images total: ' + str(len(images)))
print('Dimensions of a single image: ' + str(images[0].shape))

#Image dimensions: Height, Width, No_of_Channels, No_of_Images
height = images[0].shape[0] #images[0] denotes the first image out of the dataset. We chose any image because all are same size
width = images[0].shape[1]
n_channels = images[0].shape[2]
n_images = len(images)
n_classes = 4

print(height)
print(width)
print(n_channels)

#Now we need to fetch the LABELS separately from the Excel labels.csv
labels = pd.read_csv(path + '/labels.csv', usecols = ['category'])

labels.iloc[0:5,]

#Building CNN model
model = Sequential()
model.reset_states()

#Initializers
initializer_glorot_u = glorot_uniform(seed = 123)

#Adding Convolution layers
model.add(Conv3D(filters = 10, kernel_size = (3,3,3), strides=(1, 1, 1), input_shape = (images[0].shape), 
                 padding='same', data_format="channels_last", activation=None, use_bias=True, #data_format: "channels_last" corresponds to inputs with shape  (batch, spatial_dim1, spatial_dim2, spatial_dim3, channels) while "channels_first" corresponds to inputs with shape  (batch, channels, spatial_dim1, spatial_dim2, spatial_dim3) 
                 kernel_initializer='glorot_uniform', 
                 bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,
                 kernel_constraint=None, bias_constraint=None))
model.add(Conv3D(filters = 10, kernel_size = (3,3,3), strides=(1, 1, 1),
                 padding='same', data_format=None, activation=None, use_bias=True, #dilation_rate=(1, 1, 1), 
                 kernel_initializer='glorot_uniform', 
                 bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,
                 kernel_constraint=None, bias_constraint=None))
model.add(MaxPooling3D(pool_size=(2, 2, 1), strides=None, padding='valid', data_format=None))

#Adding Multi-Layer Perceptron layers
model.add(Dense(10, activation='sigmoid', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', 
                kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, 
                bias_constraint=None))
model.add(Dense(n_classes, activation='softmax', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', 
                kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, 
                bias_constraint=None))

#Print model architecture (Layers architecture)
print(model.summary())

#Compile model
model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])
          
#Fit model to the data
callback_ES = EarlyStopping(monitor='val_loss', min_delta=0)
model.fit(images, ('1','0','0','0'), batch_size=32, epochs=5,
                   #validation_data=(X_test, y_test), 
          callbacks = [callback_ES])
#Evaluate
# model.evaluate(X_test, y_test)



References:
1. Keras Documentation
https://keras.io/

2. Scikit-Image documentation
http://scikit-image.org/docs/0.7.0/api/skimage.io.collection.html
